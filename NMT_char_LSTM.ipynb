{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_char_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf-vm63jR0XX"
      },
      "source": [
        "import numpy as np\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input,LSTM,Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPWMKA7LsszC",
        "outputId": "78d2c9e0-e40e-45c0-fabb-1e37fa9cf72c"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip\r\n",
        "!!unzip fra-eng.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  fra-eng.zip',\n",
              " '  inflating: _about.txt              ',\n",
              " '  inflating: fra.txt                 ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUa8f3sQszHM"
      },
      "source": [
        "batch_size = 64  # Batch size for training.\r\n",
        "epochs = 100  # Number of epochs to train for.\r\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\r\n",
        "num_samples = 10000  # Number of samples to train on.\r\n",
        "# Path to the data txt file on disk.\r\n",
        "data_path = \"fra.txt\""
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uvby8SeR96y"
      },
      "source": [
        "# Vectorize the data.\r\n",
        "input_texts = []\r\n",
        "target_texts = []\r\n",
        "input_characters = set()\r\n",
        "target_characters = set()\r\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\r\n",
        "    lines = f.read().split(\"\\n\")\r\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\r\n",
        "    input_text, target_text,_ = line.split(\"\\t\")\r\n",
        "    # print(input_text)\r\n",
        "\r\n",
        "    # We use \"tab\" as the \"start sequence\" character\r\n",
        "    # for the targets tab and \"\\n\" as \"end sequence\" character.\r\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\r\n",
        "    input_texts.append(input_text)\r\n",
        "    target_texts.append(target_text)\r\n",
        "    for char in input_text:\r\n",
        "        if char not in input_characters:\r\n",
        "            input_characters.add(char)\r\n",
        "    for char in target_text:\r\n",
        "        if char not in target_characters:\r\n",
        "            target_characters.add(char)\r\n",
        "\r\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3PFfRTnsHZl"
      },
      "source": [
        "# input_characters"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJDKTzzQR-js"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\r\n",
        "target_characters = sorted(list(target_characters))\r\n",
        "num_encoder_tokens = len(input_characters)\r\n",
        "num_decoder_tokens = len(target_characters)\r\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\r\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMsXFohjR-vN",
        "outputId": "11fb23b9-a80b-4b94-ca38-f2ccd697cd10"
      },
      "source": [
        "print(\"Number of samples:\", len(input_texts))\r\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\r\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\r\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\r\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 93\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nji3AOqUR_Fz"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\r\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_OUeDsSx18g"
      },
      "source": [
        "# input_token_index"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2OfzdLwR_Vz"
      },
      "source": [
        "encoder_input_data = np.zeros(\r\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n",
        "decoder_input_data = np.zeros(\r\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n",
        "decoder_target_data = np.zeros(\r\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiGD4_cER_fR"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\r\n",
        "    for t, char in enumerate(input_text):\r\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\r\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\r\n",
        "    \r\n",
        "    for t, char in enumerate(target_text):\r\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\r\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\r\n",
        "        if t > 0:\r\n",
        "            # decoder_target_data will be ahead by one timestep\r\n",
        "            # and will not include the start character.\r\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\r\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\r\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcokIu5KR_6P"
      },
      "source": [
        "# Define an input sequence and process it.\r\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\r\n",
        "encoder = LSTM(latent_dim, return_state=True)\r\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\r\n",
        "\r\n",
        "# We discard `encoder_outputs` and only keep the states.\r\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3pstBowSAbL"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\r\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\r\n",
        "\r\n",
        "# We set up our decoder to return full output sequences,\r\n",
        "# and to return internal states as well. We don't use the\r\n",
        "# return states in the training model, but we will use them in inference.\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\r\n",
        "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fAZB9UgSA32"
      },
      "source": [
        "# Define the model that will turn\r\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGmI7w96SBew",
        "outputId": "be55aafc-2402-4fd8-c1da-c47895b6f255"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\r\n",
        ")\r\n",
        "model.fit(\r\n",
        "    [encoder_input_data, decoder_input_data],\r\n",
        "    decoder_target_data,\r\n",
        "    batch_size=batch_size,\r\n",
        "    epochs=epochs,\r\n",
        "    validation_split=0.2,\r\n",
        ")\r\n",
        "# Save model\r\n",
        "# model.save(\"s2s\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 55s 419ms/step - loss: 1.4914 - accuracy: 0.6968 - val_loss: 1.0769 - val_accuracy: 0.7143\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 49s 390ms/step - loss: 0.8758 - accuracy: 0.7625 - val_loss: 0.8268 - val_accuracy: 0.7731\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.6906 - accuracy: 0.8084 - val_loss: 0.7049 - val_accuracy: 0.7987\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.5990 - accuracy: 0.8270 - val_loss: 0.6377 - val_accuracy: 0.8124\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.5379 - accuracy: 0.8424 - val_loss: 0.5975 - val_accuracy: 0.8275\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.5000 - accuracy: 0.8534 - val_loss: 0.5653 - val_accuracy: 0.8352\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.4679 - accuracy: 0.8614 - val_loss: 0.5468 - val_accuracy: 0.8399\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.4448 - accuracy: 0.8686 - val_loss: 0.5257 - val_accuracy: 0.8447\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.4242 - accuracy: 0.8735 - val_loss: 0.5114 - val_accuracy: 0.8485\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.4027 - accuracy: 0.8794 - val_loss: 0.4984 - val_accuracy: 0.8524\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.3891 - accuracy: 0.8833 - val_loss: 0.4874 - val_accuracy: 0.8569\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.3734 - accuracy: 0.8876 - val_loss: 0.4819 - val_accuracy: 0.8583\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.3582 - accuracy: 0.8923 - val_loss: 0.4697 - val_accuracy: 0.8610\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.3443 - accuracy: 0.8965 - val_loss: 0.4661 - val_accuracy: 0.8633\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 49s 389ms/step - loss: 0.3292 - accuracy: 0.9007 - val_loss: 0.4583 - val_accuracy: 0.8664\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.3181 - accuracy: 0.9039 - val_loss: 0.4566 - val_accuracy: 0.8659\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.3060 - accuracy: 0.9077 - val_loss: 0.4509 - val_accuracy: 0.8681\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.2955 - accuracy: 0.9101 - val_loss: 0.4481 - val_accuracy: 0.8703\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.2848 - accuracy: 0.9141 - val_loss: 0.4481 - val_accuracy: 0.8704\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.2726 - accuracy: 0.9182 - val_loss: 0.4503 - val_accuracy: 0.8699\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.2628 - accuracy: 0.9207 - val_loss: 0.4479 - val_accuracy: 0.8708\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.2557 - accuracy: 0.9232 - val_loss: 0.4435 - val_accuracy: 0.8733\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 52s 412ms/step - loss: 0.2450 - accuracy: 0.9258 - val_loss: 0.4488 - val_accuracy: 0.8729\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.2369 - accuracy: 0.9285 - val_loss: 0.4493 - val_accuracy: 0.8734\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 53s 427ms/step - loss: 0.2305 - accuracy: 0.9295 - val_loss: 0.4490 - val_accuracy: 0.8744\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2177 - accuracy: 0.9340 - val_loss: 0.4528 - val_accuracy: 0.8743\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.2149 - accuracy: 0.9348 - val_loss: 0.4516 - val_accuracy: 0.8743\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 53s 422ms/step - loss: 0.2070 - accuracy: 0.9369 - val_loss: 0.4539 - val_accuracy: 0.8746\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 53s 422ms/step - loss: 0.1992 - accuracy: 0.9397 - val_loss: 0.4550 - val_accuracy: 0.8749\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.1931 - accuracy: 0.9414 - val_loss: 0.4647 - val_accuracy: 0.8736\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1861 - accuracy: 0.9431 - val_loss: 0.4664 - val_accuracy: 0.8749\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1801 - accuracy: 0.9452 - val_loss: 0.4688 - val_accuracy: 0.8746\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.1751 - accuracy: 0.9463 - val_loss: 0.4724 - val_accuracy: 0.8746\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.1696 - accuracy: 0.9481 - val_loss: 0.4783 - val_accuracy: 0.8748\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.1656 - accuracy: 0.9495 - val_loss: 0.4793 - val_accuracy: 0.8750\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.1609 - accuracy: 0.9508 - val_loss: 0.4889 - val_accuracy: 0.8742\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 53s 427ms/step - loss: 0.1539 - accuracy: 0.9534 - val_loss: 0.4928 - val_accuracy: 0.8739\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 49s 391ms/step - loss: 0.1496 - accuracy: 0.9543 - val_loss: 0.4886 - val_accuracy: 0.8752\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 48s 386ms/step - loss: 0.1450 - accuracy: 0.9555 - val_loss: 0.4979 - val_accuracy: 0.8746\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 49s 393ms/step - loss: 0.1414 - accuracy: 0.9569 - val_loss: 0.5017 - val_accuracy: 0.8752\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 48s 383ms/step - loss: 0.1372 - accuracy: 0.9583 - val_loss: 0.5061 - val_accuracy: 0.8753\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1325 - accuracy: 0.9596 - val_loss: 0.5105 - val_accuracy: 0.8746\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.1288 - accuracy: 0.9603 - val_loss: 0.5086 - val_accuracy: 0.8758\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.5178 - val_accuracy: 0.8754\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.1226 - accuracy: 0.9623 - val_loss: 0.5196 - val_accuracy: 0.8758\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.1190 - accuracy: 0.9636 - val_loss: 0.5268 - val_accuracy: 0.8756\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.1156 - accuracy: 0.9646 - val_loss: 0.5306 - val_accuracy: 0.8748\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.5371 - val_accuracy: 0.8742\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 53s 426ms/step - loss: 0.1106 - accuracy: 0.9659 - val_loss: 0.5396 - val_accuracy: 0.8749\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.1098 - accuracy: 0.9660 - val_loss: 0.5523 - val_accuracy: 0.8732\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 53s 423ms/step - loss: 0.1056 - accuracy: 0.9674 - val_loss: 0.5469 - val_accuracy: 0.8738\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.1033 - accuracy: 0.9681 - val_loss: 0.5568 - val_accuracy: 0.8748\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 53s 422ms/step - loss: 0.1000 - accuracy: 0.9688 - val_loss: 0.5576 - val_accuracy: 0.8741\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 52s 420ms/step - loss: 0.0982 - accuracy: 0.9694 - val_loss: 0.5637 - val_accuracy: 0.8736\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 53s 426ms/step - loss: 0.0963 - accuracy: 0.9702 - val_loss: 0.5678 - val_accuracy: 0.8734\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 54s 429ms/step - loss: 0.0949 - accuracy: 0.9705 - val_loss: 0.5834 - val_accuracy: 0.8727\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 53s 423ms/step - loss: 0.0923 - accuracy: 0.9710 - val_loss: 0.5795 - val_accuracy: 0.8743\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 54s 430ms/step - loss: 0.0900 - accuracy: 0.9720 - val_loss: 0.5854 - val_accuracy: 0.8727\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 53s 428ms/step - loss: 0.0880 - accuracy: 0.9726 - val_loss: 0.5912 - val_accuracy: 0.8738\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.0856 - accuracy: 0.9733 - val_loss: 0.5961 - val_accuracy: 0.8728\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 53s 427ms/step - loss: 0.0840 - accuracy: 0.9734 - val_loss: 0.6009 - val_accuracy: 0.8726\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.0813 - accuracy: 0.9741 - val_loss: 0.6054 - val_accuracy: 0.8722\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.0801 - accuracy: 0.9745 - val_loss: 0.6070 - val_accuracy: 0.8734\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.6153 - val_accuracy: 0.8733\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.0774 - accuracy: 0.9751 - val_loss: 0.6166 - val_accuracy: 0.8725\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.0757 - accuracy: 0.9757 - val_loss: 0.6153 - val_accuracy: 0.8733\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 53s 425ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.6228 - val_accuracy: 0.8731\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 53s 422ms/step - loss: 0.0727 - accuracy: 0.9766 - val_loss: 0.6261 - val_accuracy: 0.8733\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0718 - accuracy: 0.9767 - val_loss: 0.6307 - val_accuracy: 0.8729\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 49s 395ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 0.6390 - val_accuracy: 0.8726\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.6386 - val_accuracy: 0.8720\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 0.6451 - val_accuracy: 0.8729\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.0658 - accuracy: 0.9786 - val_loss: 0.6473 - val_accuracy: 0.8719\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 54s 431ms/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.6547 - val_accuracy: 0.8719\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 53s 426ms/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.6592 - val_accuracy: 0.8722\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 0.6587 - val_accuracy: 0.8720\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 53s 422ms/step - loss: 0.0617 - accuracy: 0.9797 - val_loss: 0.6620 - val_accuracy: 0.8718\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 53s 423ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 0.6670 - val_accuracy: 0.8729\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 53s 421ms/step - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.6714 - val_accuracy: 0.8724\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 54s 436ms/step - loss: 0.0588 - accuracy: 0.9807 - val_loss: 0.6848 - val_accuracy: 0.8709\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.6811 - val_accuracy: 0.8721\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 52s 413ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.6816 - val_accuracy: 0.8723\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 52s 419ms/step - loss: 0.0557 - accuracy: 0.9813 - val_loss: 0.6895 - val_accuracy: 0.8723\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 53s 423ms/step - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.6885 - val_accuracy: 0.8722\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 52s 418ms/step - loss: 0.0542 - accuracy: 0.9817 - val_loss: 0.6850 - val_accuracy: 0.8728\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 0.7018 - val_accuracy: 0.8720\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.7001 - val_accuracy: 0.8716\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.7049 - val_accuracy: 0.8723\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0517 - accuracy: 0.9824 - val_loss: 0.7065 - val_accuracy: 0.8727\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 0.7109 - val_accuracy: 0.8714\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 0.7138 - val_accuracy: 0.8721\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.7147 - val_accuracy: 0.8721\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0478 - accuracy: 0.9837 - val_loss: 0.7197 - val_accuracy: 0.8722\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.7201 - val_accuracy: 0.8717\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0470 - accuracy: 0.9837 - val_loss: 0.7248 - val_accuracy: 0.8715\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 53s 420ms/step - loss: 0.0464 - accuracy: 0.9838 - val_loss: 0.7294 - val_accuracy: 0.8714\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.7320 - val_accuracy: 0.8716\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.7343 - val_accuracy: 0.8722\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.7422 - val_accuracy: 0.8710\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0438 - accuracy: 0.9845 - val_loss: 0.7393 - val_accuracy: 0.8721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe44d0236d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UoYyIffRvL2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}